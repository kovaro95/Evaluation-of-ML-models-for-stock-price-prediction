{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "\r\n",
    "import talib\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import ElasticNet\r\n",
    "\r\n",
    "from tensorflow import keras\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Activation,Dropout,Dense,LSTM,BatchNormalization\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "RANDOM_SEED=42\r\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df=pd.read_csv(f\"../Data/Prices/AAPL_min.csv\",index_col=0)\r\n",
    "thirt_min=pd.read_csv(f\"../Data/Prices/AAPL_thirt_min.csv\",index_col=0)\r\n",
    "hour=pd.read_csv(f\"../Data/Prices/AAPL_hour.csv\",index_col=0)\r\n",
    "daily=pd.read_csv(f\"../Data/Prices/AAPL_daily.csv\",index_col=0)\r\n",
    "weekly=pd.read_csv(f\"../Data/Prices/AAPL_weekly.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sliding_windows(data,seq_length=5):\r\n",
    "    xs=[]\r\n",
    "    \r\n",
    "    for i in range(len(data)-seq_length-1):\r\n",
    "        x=data[i:(i+seq_length)]\r\n",
    "        xs.append(x)\r\n",
    "    return np.array(xs)\r\n",
    "\r\n",
    "def Data_preparation(df,data_size=500,scale=True):\r\n",
    "    data=df.dropna(how=\"all\",axis=0)\r\n",
    "    data=data.iloc[-data_size:]\r\n",
    "    data[\"Target\"]=data[\"Close\"].shift(-1)\r\n",
    "    data.drop([\"Dividends\",\"Stock Splits\"],axis=1,inplace=True)\r\n",
    "    \r\n",
    "    sma15=df[\"Close\"].transform(lambda x: x.rolling(window=15).mean())\r\n",
    "    sma5=df[\"Close\"].transform(lambda x: x.rolling(window=5).mean())\r\n",
    "    rsi=talib.RSI(df[\"Close\"])\r\n",
    "    mfi=talib.MFI(df[\"High\"],df[\"Low\"],df[\"Close\"],df[\"Volume\"])\r\n",
    "    obv=talib.OBV(df[\"Close\"],df[\"Volume\"])\r\n",
    "    atr=talib.ATR(df[\"High\"],df[\"Low\"],df[\"Close\"],14)\r\n",
    "    logret=np.log1p(df.Close.pct_change())\r\n",
    "       \r\n",
    "    n=len(data)\r\n",
    "    s1=int(n*0.8)\r\n",
    "    train=data.iloc[:s1,:]\r\n",
    "    test=data.iloc[s1:,:]\r\n",
    "        \r\n",
    "    if scale==True:\r\n",
    "        scaler=MinMaxScaler()\r\n",
    "        scaler=scaler.fit(train)\r\n",
    "        \r\n",
    "        train=scaler.transform(train)\r\n",
    "        test=scaler.transform(test)\r\n",
    "    \r\n",
    "    #train[[\"SMA15\",\"SMA5\",\"RSI\",\"MFI\",\"OBV\",\"ATR\",\"Log return\"]]=[sma15[:s1],sma5[:s1],rsi[:s1],mfi[:s1],obv[:s1],atr[:s1],logret[:s1]]\r\n",
    "    #test[[\"SMA15\",\"SMA5\",\"RSI\",\"MFI\",\"OBV\",\"ATR\",\"Log return\"]]=[sma15[s1:],sma5[s1:],rsi[s1:],mfi[s1:],obv[s1:],atr[s1:],logret[s1:]]\r\n",
    "    \r\n",
    "    return train.drop(\"Target\",axis=1),test.drop(\"Target\",axis=1),train.iloc[:,-1],test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=Data_preparation(daily,scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(len_ts, hidden_neurons = 10, nfeature=1, batch_size=None,stateful=False):\r\n",
    "    in_out_neurons = 1\r\n",
    "    \r\n",
    "    inp = layers.Input(batch_shape= (batch_size, len_ts, nfeature),\r\n",
    "                       name=\"input\")  \r\n",
    "\r\n",
    "    rnn = layers.LSTM(hidden_neurons, \r\n",
    "                    return_sequences=True,\r\n",
    "                    stateful=stateful,\r\n",
    "                    name=\"RNN\")(inp)\r\n",
    "\r\n",
    "    dens = layers.TimeDistributed(layers.Dense(in_out_neurons,name=\"dense\"))(rnn)\r\n",
    "    model = models.Model(inputs=[inp],outputs=[dens])\r\n",
    "    \r\n",
    "    model.compile(loss=\"mean_squared_error\",\r\n",
    "                  sample_weight_mode=\"temporal\",\r\n",
    "                  optimizer=\"rmsprop\")\r\n",
    "    return(model,(inp,rnn,dens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/predicting-stock-prices-using-a-keras-lstm-model-4225457f0233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-570eaa370ed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_slided\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSliding_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_slided\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSliding_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_train_slided\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_slided\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_slided=torch.from_numpy(Sliding_windows(X_train)).float()\r\n",
    "X_test_slided=torch.from_numpy(Sliding_windows(X_train)).float()\r\n",
    "y_train_slided=torch.from_numpy(np.asarray(y_train)).float()\r\n",
    "y_test_slided=torch.from_numpy(np.asarray(y_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\r\n",
    "    def __init__(self,input_dim,hidden_dim,seq_length,num_layers=2):\r\n",
    "        super(LSTM_model,self).__init__()\r\n",
    "        \r\n",
    "        self.input_dim=input_dim\r\n",
    "        self.hidden_dim=hidden_dim\r\n",
    "        self.seq_length=seq_length\r\n",
    "        self.num_layers=num_layers\r\n",
    "        \r\n",
    "        self.lstm=nn.LSTM(\r\n",
    "            input_size=input_dim,\r\n",
    "            hidden_size=hidden_dim,\r\n",
    "            num_layers=num_layers,\r\n",
    "            dropout=0.5\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.linear=nn.Linear(in_features=hidden_dim,out_features=1)\r\n",
    "        \r\n",
    "    def reset_hidden_state(self):\r\n",
    "        self.hidden=(\r\n",
    "            torch.zeros(self.num_layers,self.seq_length,self.hidden_dim),\r\n",
    "            torch.zeros(self.num_layers,self.seq_length,self.hidden_dim)\r\n",
    "        )\r\n",
    "    def forward(self,input):\r\n",
    "        lstm_out, _ =self.lstm(\r\n",
    "            input.view(len(input),self.seq_length,-1),\r\n",
    "            self.hidden\r\n",
    "        )\r\n",
    "        \r\n",
    "        y_pred=self.linear(\r\n",
    "            lstm_out.view(self.seq_length,len(input),self.hidden_dim)[-1]    \r\n",
    "        )\r\n",
    "        return y_pred\r\n",
    "            \r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data,train_labels,test_data=None,test_labels=None):\r\n",
    "    loss_fn=nn.MSELoss(reduction=\"sum\")\r\n",
    "    \r\n",
    "    optimiser=optim.Adam(model.parameters(), lr=1e-3)\r\n",
    "    \r\n",
    "    num_epochs=60\r\n",
    "    \r\n",
    "    train_hist=np.zeros(num_epochs)\r\n",
    "    test_hist=np.zeros(num_epochs)\r\n",
    "    \r\n",
    "    for t in range(num_epochs):\r\n",
    "        model.reset_hidden_state()\r\n",
    "        y_pred=model(X_train_slided)\r\n",
    "        loss=loss_fn(y_pred.float(),y_train_slided)\r\n",
    "        \r\n",
    "        if test_data is not None:\r\n",
    "            with torch.no_grad():\r\n",
    "                y_test_pred=model(X_test_slided)\r\n",
    "                test_loss=loss_fn(y_test_pred.float(),y_test_slided)\r\n",
    "            test_hist[t]=test_loss.item()\r\n",
    "            \r\n",
    "            if t % 10 ==0:\r\n",
    "                print(f\"Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}\")\r\n",
    "        elif t%10==0:\r\n",
    "            print(f\"Epoch {t} train loss: {loss.item()}\")\r\n",
    "        \r\n",
    "        train_hist[t]=loss.item()\r\n",
    "        optimiser.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimiser.step()\r\n",
    "        \r\n",
    "    return model.eval(), train_hist, test_hist\r\n",
    "        \r\n",
    "    \r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LSTM_model(5,200,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([394, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "D:\\Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([394, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 842494848.0 test loss: nan\n",
      "Epoch 10 train loss: 740598464.0 test loss: nan\n",
      "Epoch 20 train loss: 663491456.0 test loss: nan\n",
      "Epoch 30 train loss: 612794624.0 test loss: nan\n",
      "Epoch 40 train loss: 570038016.0 test loss: nan\n",
      "Epoch 50 train loss: 531231744.0 test loss: nan\n"
     ]
    }
   ],
   "source": [
    "model, train_hist,test_hist=train_model(model,X_train_slided,y_train_slided,X_test_slided,y_test_slided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([394, 5]), torch.Size([394, 5, 5]))"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_slided.shape,X_test_slided.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=8A6TEjG2DNw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "95ab7303ed2746327945aa376054eddca8c4eca362915ff95db932dbe7e7ee41"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}