{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\r\n",
    "\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "params = {'legend.fontsize': 'x-large',\r\n",
    "          'figure.figsize': (15, 15/1.6),\r\n",
    "         'axes.labelsize': 'x-large',\r\n",
    "         'axes.titlesize':'x-large',\r\n",
    "         'xtick.labelsize':'x-large',\r\n",
    "         'ytick.labelsize':'x-large'}\r\n",
    "plt.rcParams.update(params)\r\n",
    "\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import yfinance as yf\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\r\n",
    "\r\n",
    "from keras.models import Model\r\n",
    "from keras.models import Sequential\r\n",
    "from keras import optimizers\r\n",
    "from keras import layers\r\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_hat,y_pred):\r\n",
    "    mape = np.mean(np.abs((y_hat - y_pred)/y_hat))*100\r\n",
    "    return mape\r\n",
    "\r\n",
    "def RMSE(y_hat,y_pred):\r\n",
    "    MSE = np.square(np.subtract(y_hat,y_pred)).mean() \r\n",
    "    return (MSE**(1/2))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_dev=tf.config.list_physical_devices(\"GPU\")\r\n",
    "if len(phys_dev)!=0:\r\n",
    "    tf.config.experimental.set_memory_growth(phys_dev[0],True)    \r\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')),\"\\n\",\"Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\r\n",
    "EPOCHS=30\r\n",
    "BATCH_SIZE=256\r\n",
    "RANDOMSEED=123\r\n",
    "SELECTED_STOCK='MSFT'\r\n",
    "\r\n",
    "\r\n",
    "np.random.seed(RANDOMSEED)\r\n",
    "python_random.seed(RANDOMSEED)\r\n",
    "tf.random.set_seed(RANDOMSEED)\r\n",
    "\r\n",
    "gme=yf.Ticker('GME').history(start='2010-01-01',end='2021-01-01')\r\n",
    "msft=yf.Ticker('MSFT').history(start='2010-01-01',end='2021-01-01')\r\n",
    "stock=yf.Ticker(SELECTED_STOCK).history(start='2010-01-01',end='2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\r\n",
    "    def __init__(self, data, target='Close',timeseries=True,scale=True,look_forw=1,look_back=60,test_size=0.2):\r\n",
    "    #Store the raw data.    \r\n",
    "        self.split=int(len(data)*(1-test_size))\r\n",
    "        self.Scaler=None\r\n",
    "        self.target_col=data.columns.get_loc(target)\r\n",
    "        self.look_forw = look_forw\r\n",
    "        self.look_back=look_back\r\n",
    "        self.train_dates=data.iloc[:self.split,:].index\r\n",
    "        self.test_dates=data.iloc[self.split-self.look_back:,:].index\r\n",
    "\r\n",
    "        #self.Data=data.dropna(subset=['Close'],how='any')   \r\n",
    "        \r\n",
    "        self.Train = np.array(data.iloc[:self.split,:])\r\n",
    "        self.Test = np.array(data.iloc[self.split-self.look_back:,:])\r\n",
    "\r\n",
    "        if timeseries==True:\r\n",
    "            self.Train=self.Train[:,self.target_col].reshape(-1,1)\r\n",
    "            self.Test=self.Test[:,self.target_col].reshape(-1,1)  \r\n",
    "        \r\n",
    "        if scale==True:\r\n",
    "            self.Scaler=MinMaxScaler(feature_range = (-1, 1))\r\n",
    "            self.Scaler=self.Scaler.fit(self.Train)\r\n",
    "        \r\n",
    "            self.Train=self.Scaler.transform(self.Train)\r\n",
    "            self.Test=self.Scaler.transform(self.Test)\r\n",
    "        \r\n",
    "        self.X_train_seq=[]\r\n",
    "        self.y_train_seq=[]\r\n",
    "        for i in range(self.look_back,len(self.Train)):\r\n",
    "            self.X_train_seq.append(self.Train[i-self.look_back:i,:])\r\n",
    "                \r\n",
    "            if timeseries==True:\r\n",
    "                self.y_train_seq.append(self.Train[i:i+self.look_forw])\r\n",
    "            else:\r\n",
    "                self.y_train_seq.append(self.Train[i:i+self.look_forw,self.target_col])\r\n",
    "\r\n",
    "        self.X_train_seq=np.array(self.X_train_seq).astype('float32')\r\n",
    "        self.y_train_seq=np.array(self.y_train_seq,dtype='object').astype('float32')\r\n",
    "\r\n",
    "        self.X_train_seq=self.X_train_seq.reshape(self.X_train_seq.shape[0],self.X_train_seq.shape[1],self.X_train_seq.shape[2])\r\n",
    "\r\n",
    "        self.X_test_seq=[]\r\n",
    "        for i in range(self.look_back,len(self.Test)):\r\n",
    "                self.X_test_seq.append(self.Test[i-self.look_back:i,:])\r\n",
    "                \r\n",
    "        self.X_test_seq=np.asarray(self.X_test_seq).astype('float32')\r\n",
    "        self.X_test_seq=self.X_test_seq.reshape(self.X_test_seq.shape[0],self.X_test_seq.shape[1],self.X_test_seq.shape[2])\r\n",
    "\r\n",
    "        print(self.__repr__())\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return '\\n'.join([\r\n",
    "        f'Original train and test{self.Train.shape,self.Test.shape}',\r\n",
    "        f'X train size {self.X_train_seq.shape}',\r\n",
    "        f'Y train size: {self.y_train_seq.shape}',\r\n",
    "        f'X test size: {self.X_test_seq.shape}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_data=Dataset(stock,look_back=60,timeseries=True,scale=True)\r\n",
    "bench_input_shape=(bench_data.look_back,bench_data.X_train_seq.shape[2])\r\n",
    "data=Dataset(stock,look_back=60,timeseries=False,scale=True)\r\n",
    "true_stock=stock.Close[data.split:].values\r\n",
    "input_shape=(data.look_back,data.X_train_seq.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mape=tf.keras.metrics.MeanAbsolutePercentageError()\r\n",
    "_rmse=tf.keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n",
    "\r\n",
    "benchmark_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=bench_input_shape),\r\n",
    "    layers.LSTM(units=50, return_sequences=False),\r\n",
    "    layers.Dense(units=1,activation='linear')\r\n",
    "])   \r\n",
    "\r\n",
    "benchmark_lstm.compile(optimizer=bench_optimizer,loss=['mse'],metrics=[_mape])\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "\r\n",
    "benchmark_history=benchmark_lstm.fit(bench_data.X_train_seq,bench_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.1\r\n",
    "                )\r\n",
    "\r\n",
    "preds_scaled=benchmark_lstm.predict(bench_data.X_test_seq)\r\n",
    "preds=bench_data.Scaler.inverse_transform(np.repeat(preds_scaled,bench_data.Train.shape[1],axis=1))\r\n",
    "benchmark_preds=preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLBACKS\r\n",
    "es=EarlyStopping(monitor='val_loss',min_delta=1e-2,mode=\"min\",patience=5,verbose=1)\r\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss',min_delta=1e-2,factor=0.75,cooldown=5,mode='min',patience=3,verbose=1)\r\n",
    "\r\n",
    "#PARAMS\r\n",
    "drop_rate=0.8\r\n",
    "activation_func='elu'\r\n",
    "\r\n",
    "kernel_reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01)\r\n",
    "bias_reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01)\r\n",
    "recurrent_reg=keras.regularizers.l1_l2(l1=0.001, l2=0.001)\r\n",
    "act_reg=keras.regularizers.l1_l2(l1=0.001, l2=0.001)\r\n",
    "\r\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=input_shape,activation=activation_func\r\n",
    "                ,kernel_regularizer=kernel_reg,bias_regularizer=bias_reg\r\n",
    "                ),\r\n",
    "    layers.Dropout(drop_rate),\r\n",
    "    layers.LSTM(units=50, return_sequences=False\r\n",
    "                #,activation=activation_func\r\n",
    "                ),\r\n",
    "    layers.Dropout(drop_rate),\r\n",
    "    layers.Dense(units=1,activation='linear')\r\n",
    "]) \r\n",
    "  \r\n",
    "opt_lstm.compile(optimizer=optimizer,loss=['mse'],metrics=[_mape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\r\n",
    "opt_history=opt_lstm.fit(data.X_train_seq,data.y_train_seq,\r\n",
    "                epochs=500,\r\n",
    "                batch_size=512,\r\n",
    "                validation_split=0.1,\r\n",
    "                verbose=0,\r\n",
    "                callbacks=[es,rlr]\r\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_scaled=opt_lstm.predict(data.X_test_seq)\r\n",
    "preds=data.Scaler.inverse_transform(np.repeat(preds_scaled,data.Train.shape[1],axis=1))\r\n",
    "opt_preds=preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,figsize=(15,15/1.6), constrained_layout=True)\r\n",
    "fig.suptitle('Loss and accuracy during training',fontsize=20)\r\n",
    "\r\n",
    "axs[0].plot(opt_history.history['loss'],label='Training loss')\r\n",
    "axs[0].plot(opt_history.history['val_loss'],label='Validation loss')\r\n",
    "axs[0].set_title('Training and validation loss')\r\n",
    "axs[0].legend()\r\n",
    "\r\n",
    "axs[1].plot(opt_history.history['mean_absolute_percentage_error'],label='Training MAPE')\r\n",
    "axs[1].plot(opt_history.history['val_mean_absolute_percentage_error'],label='Validation MAPE')\r\n",
    "axs[1].set_title('Training and validation MAPE')\r\n",
    "axs[1].legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(benchmark_preds,'g-.',label=\"Unoptimized LSTM predictions\")\r\n",
    "plt.plot(opt_preds,'b-.',label=\"Optimized LSTM predictions\")\r\n",
    "plt.plot(true_stock,'r-',linewidth=2,label=\"Observed\")\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(benchmark_preds,'g-.',label=\"Unoptimized LSTM predictions\")\r\n",
    "plt.plot(opt_preds,'b-.',label=\"Optimized LSTM predictions\")\r\n",
    "plt.plot(true_stock,'r-',linewidth=2,label=\"Observed\")\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python387jvsc74a57bd095ab7303ed2746327945aa376054eddca8c4eca362915ff95db932dbe7e7ee41"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}