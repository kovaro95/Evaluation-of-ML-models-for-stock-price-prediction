{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "import datetime as dt\r\n",
    "import math\r\n",
    "\r\n",
    "import random as python_random\r\n",
    "\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.rcParams[\"figure.figsize\"] = (14,7)\r\n",
    "\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import yfinance as yf\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\r\n",
    "\r\n",
    "from keras.models import Model\r\n",
    "from keras.models import Sequential\r\n",
    "from keras import optimizers\r\n",
    "from keras.layers import Activation,Dropout,Dense,LSTM,BatchNormalization,Input,Bidirectional\r\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_hat,y_pred):\r\n",
    "    mape = np.mean(np.abs((y_hat - y_pred)/y_hat))\r\n",
    "    return \"{:.2%}\".format(mape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_hat,y_pred):\r\n",
    "    MSE = np.square(np.subtract(y_hat,y_pred)).mean() \r\n",
    "    return math.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_dev=tf.config.list_physical_devices(\"GPU\")\n",
    "if len(phys_dev)!=0:\n",
    "    tf.config.experimental.set_memory_growth(phys_dev[0],True)    \n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\r\n",
    "EPOCHS=30\r\n",
    "BATCH_SIZE=256\r\n",
    "RANDOMSEED=123\r\n",
    "SELECTED_STOCK='GME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOMSEED)\n",
    "python_random.seed(RANDOMSEED)\n",
    "tf.random.set_seed(RANDOMSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock=yf.Ticker(SELECTED_STOCK).history(start='2010-01-01',end='2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "x=np.arange(0,len(stock)).reshape(-1,1) \r\n",
    "y=stock.Close.values.reshape(-1,1)\r\n",
    "regressor=LinearRegression().fit(x,y)\r\n",
    "slope=regressor.coef_\r\n",
    "var=stock.Close.var()\r\n",
    "mean=stock.Close.mean()\r\n",
    "range_=stock.Close.max()-stock.Close.min()\r\n",
    "print('\\n'.join([\r\n",
    "    f'Close price variance: {var}',\r\n",
    "    f'Close price mean: {mean}',\r\n",
    "    f'Close price regression slope: {slope[0]}',\r\n",
    "    f'Close price range: {range_}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,label='Stock price')\r\n",
    "plt.plot(x,regressor.coef_*x+regressor.intercept_,'b-.',label='Trend line')\r\n",
    "plt.legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\r\n",
    "  def __init__(self, data, target='Close',timeseries=True,scale=True,look_forw=1,look_back=20,test_size=0.2):\r\n",
    "    #Store the raw data.    \r\n",
    "    self.split=int(len(data)*(1-test_size))\r\n",
    "    self.Scaler=None\r\n",
    "    self.target_col=data.columns.get_loc(target)\r\n",
    "    self.look_forw = look_forw\r\n",
    "    self.look_back=look_back\r\n",
    "    self.train_dates=data.iloc[:self.split,:].index\r\n",
    "    self.test_dates=data.iloc[self.split-self.look_back:,:].index\r\n",
    "\r\n",
    "    #self.Data=data.dropna(subset=['Close'],how='any')   \r\n",
    "    \r\n",
    "    self.Train = np.array(data.iloc[:self.split,:])\r\n",
    "    self.Test = np.array(data.iloc[self.split-self.look_back:,:])\r\n",
    "\r\n",
    "    if timeseries==True:\r\n",
    "      self.Train=self.Train[:,self.target_col].reshape(-1,1)\r\n",
    "      self.Test=self.Test[:,self.target_col].reshape(-1,1)  \r\n",
    "    \r\n",
    "    if scale==True:\r\n",
    "      self.Scaler=MinMaxScaler(feature_range = (0, 1))\r\n",
    "      self.Scaler=self.Scaler.fit(self.Train)\r\n",
    "    \r\n",
    "      self.Train=self.Scaler.transform(self.Train)\r\n",
    "      self.Test=self.Scaler.transform(self.Test)\r\n",
    "     \r\n",
    "    self.X_train_seq=[]\r\n",
    "    self.y_train_seq=[]\r\n",
    "    for i in range(self.look_back,len(self.Train)):\r\n",
    "            self.X_train_seq.append(self.Train[i-self.look_back:i,:])\r\n",
    "            \r\n",
    "            if timeseries==True:\r\n",
    "              self.y_train_seq.append(self.Train[i])\r\n",
    "            else:\r\n",
    "              self.y_train_seq.append(self.Train[i,self.target_col])\r\n",
    "\r\n",
    "    self.X_train_seq=np.array(self.X_train_seq)\r\n",
    "    self.y_train_seq=np.array(self.y_train_seq)\r\n",
    "\r\n",
    "    self.X_train_seq=self.X_train_seq.reshape(self.X_train_seq.shape[0],self.X_train_seq.shape[1],self.X_train_seq.shape[2])\r\n",
    "\r\n",
    "    self.X_test_seq=[]\r\n",
    "    for i in range(self.look_back,len(self.Test)):\r\n",
    "            self.X_test_seq.append(self.Test[i-self.look_back:i,:])\r\n",
    "            \r\n",
    "    self.X_test_seq=np.asarray(self.X_test_seq)\r\n",
    "    self.X_test_seq=self.X_test_seq.reshape(self.X_test_seq.shape[0],self.X_test_seq.shape[1],self.X_test_seq.shape[2])\r\n",
    "\r\n",
    "    print(self.__repr__())\r\n",
    "\r\n",
    "  def __repr__(self):\r\n",
    "    return '\\n'.join([\r\n",
    "    f'Original train and test{self.Train.shape,self.Test.shape}',\r\n",
    "    f'X train size {self.X_train_seq.shape}',\r\n",
    "    f'Y train size: {self.y_train_seq.shape}',\r\n",
    "    f'X test size: {self.X_test_seq.shape}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_data=Dataset(stock,look_back=1,timeseries=True)\r\n",
    "med_data=Dataset(stock,look_back=60,timeseries=True)\r\n",
    "long_data=Dataset(stock,look_back=120,timeseries=True)\r\n",
    "true_stock=stock.Close[long_data.split:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape,neurons,layer_num=2):\r\n",
    "    lstm_model = Sequential()\r\n",
    "    if layer_num==1:\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=False,input_shape=input_shape))\r\n",
    "    if layer_num==2:\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=True,input_shape=input_shape))\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=False))\r\n",
    "    elif layer_num==4:\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=True,input_shape=input_shape))\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=True))\r\n",
    "        lstm_model.add(LSTM(units=neurons, return_sequences=False))\r\n",
    "    \r\n",
    "    lstm_model.add(Dense(units=1,activation='linear'))\r\n",
    "        \r\n",
    "    \r\n",
    "    #defined_metrics = [tf.keras.metrics.MeanSquaredError(name='MSE')]\r\n",
    "    \r\n",
    "    # Compile the model\r\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n",
    "    lstm_model.compile(optimizer=optimizer,loss=['mse'],metrics=['accuracy'])\r\n",
    "    \r\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Models={}\r\n",
    "LSTM_Preds={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=10\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "short_shallow_lstm=LSTM_model(input_shape=(short_data.look_back,short_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "\r\n",
    "es=EarlyStopping(monitor='val_loss',min_delta=1e-10,patience=10,verbose=1)\r\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=10,verbose=1)\r\n",
    "mcp=ModelCheckpoint(filepath='weights.h5',monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=True)\r\n",
    "tb=TensorBoard('logs')\r\n",
    "\r\n",
    "short_shallow_lstm_hist=short_shallow_lstm.fit(short_data.X_train_seq,short_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "med_shallow_lstm=LSTM_model(input_shape=(med_data.look_back,med_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "\r\n",
    "med_shallow_lstm_hist=med_shallow_lstm.fit(med_data.X_train_seq,med_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "long_shallow_lstm=LSTM_model(input_shape=(long_data.look_back,long_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "\r\n",
    "long_shallow_lstm_hist=long_shallow_lstm.fit(long_data.X_train_seq,long_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "long_deep_lstm=LSTM_model(input_shape=(long_data.look_back,long_data.X_train_seq.shape[2]),neurons=neurons,layer_num=4)\r\n",
    "\r\n",
    "long_deep_lstm_hist=long_deep_lstm.fit(long_data.X_train_seq,long_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=int(BATCH_SIZE/2),\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "LSTM_Models['10 neuron']=[short_shallow_lstm_hist,med_shallow_lstm_hist,long_shallow_lstm_hist, long_deep_lstm_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_data.Scaler==None:\r\n",
    "    short=short_shallow_lstm.predict(short_data.X_test_seq)\r\n",
    "    med=med_shallow_lstm.predict(med_data.X_test_seq)\r\n",
    "    long=long_shallow_lstm.predict(long_data.X_test_seq)\r\n",
    "    long_deep=long_deep_lstm.predict(long_data.X_test_seq)\r\n",
    "    \r\n",
    "else:\r\n",
    "    short_preds=np.repeat(short_shallow_lstm.predict(short_data.X_test_seq),7,axis=1)\r\n",
    "    med_preds=np.repeat(med_shallow_lstm.predict(med_data.X_test_seq),7,axis=1)\r\n",
    "    long_preds=np.repeat(long_shallow_lstm.predict(long_data.X_test_seq),7,axis=1)\r\n",
    "    long_preds_deep=np.repeat(long_deep_lstm.predict(long_data.X_test_seq),7,axis=1)\r\n",
    "    \r\n",
    "    short=short_data.Scaler.inverse_transform(short_preds)[:,0]\r\n",
    "    med=med_data.Scaler.inverse_transform(med_preds)[:,0]\r\n",
    "    long=long_data.Scaler.inverse_transform(long_preds)[:,0]\r\n",
    "    long_deep=long_data.Scaler.inverse_transform(long_preds_deep)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Preds['10 neuron']=[short,med,long,long_deep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=50\r\n",
    "es=EarlyStopping(monitor='val_loss',min_delta=1e-10,patience=10,verbose=1)\r\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=10,verbose=1)\r\n",
    "mcp=ModelCheckpoint(filepath='weights.h5',monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=True)\r\n",
    "tb=TensorBoard('logs')\r\n",
    "\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "short_shallow_lstm=LSTM_model(input_shape=(short_data.look_back,short_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "short_shallow_lstm_hist=short_shallow_lstm.fit(short_data.X_train_seq,short_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "med_shallow_lstm=LSTM_model(input_shape=(med_data.look_back,med_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "med_shallow_lstm_hist=med_shallow_lstm.fit(med_data.X_train_seq,med_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "long_shallow_lstm=LSTM_model(input_shape=(long_data.look_back,long_data.X_train_seq.shape[2]),neurons=neurons,layer_num=2)\r\n",
    "long_shallow_lstm_hist=long_shallow_lstm.fit(long_data.X_train_seq,long_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=BATCH_SIZE,\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "\r\n",
    "\r\n",
    "keras.backend.clear_session()\r\n",
    "long_deep_lstm=LSTM_model(input_shape=(long_data.look_back,long_data.X_train_seq.shape[2]),neurons=neurons,layer_num=4)\r\n",
    "long_deep_lstm_hist=long_deep_lstm.fit(long_data.X_train_seq,long_data.y_train_seq,\r\n",
    "                epochs=EPOCHS,\r\n",
    "                batch_size=int(BATCH_SIZE/2),\r\n",
    "                shuffle=False,\r\n",
    "                verbose=0,\r\n",
    "                validation_split=0.2)\r\n",
    "LSTM_Models['50 neuron']=[short_shallow_lstm_hist,med_shallow_lstm_hist,long_shallow_lstm_hist,long_deep_lstm_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_data.Scaler==None:\r\n",
    "    short=short_shallow_lstm.predict(short_data.X_test_seq)\r\n",
    "    med=med_shallow_lstm.predict(med_data.X_test_seq)\r\n",
    "    long=long_shallow_lstm.predict(long_data.X_test_seq)\r\n",
    "    long_deep=long_deep_lstm.predict(long_data.X_test_seq)\r\n",
    "    \r\n",
    "else:\r\n",
    "    short_preds=np.repeat(short_shallow_lstm.predict(short_data.X_test_seq),7,axis=1)\r\n",
    "    med_preds=np.repeat(med_shallow_lstm.predict(med_data.X_test_seq),7,axis=1)\r\n",
    "    long_preds=np.repeat(long_shallow_lstm.predict(long_data.X_test_seq),7,axis=1)\r\n",
    "    long_preds_deep=np.repeat(long_deep_lstm.predict(long_data.X_test_seq),7,axis=1)\r\n",
    "    \r\n",
    "    short=short_data.Scaler.inverse_transform(short_preds)[:,0]\r\n",
    "    med=med_data.Scaler.inverse_transform(med_preds)[:,0]\r\n",
    "    long=long_data.Scaler.inverse_transform(long_preds)[:,0]\r\n",
    "    long_deep=long_data.Scaler.inverse_transform(long_preds_deep)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Preds['50 neuron']=[short,med,long,long_deep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models={}\r\n",
    "Models['Names']=['Shallow model with sliding window=1','Shallow model with sliding window=60', 'Shallow model with sliding window=120', '\"Deep\" model with sliding window=120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, constrained_layout=True)\r\n",
    "fig.suptitle('LSTM model loss function during training')\r\n",
    "cut=-1\r\n",
    "axs[0].plot(LSTM_Models['10 neuron'][0].history['val_loss'],'g-.',label=Models['Names'][0])\r\n",
    "axs[0].plot(LSTM_Models['10 neuron'][1].history['val_loss'],'m-.',label=Models['Names'][1])\r\n",
    "axs[0].plot(LSTM_Models['10 neuron'][2].history['val_loss'],'b-.',label=Models['Names'][2])\r\n",
    "axs[0].plot(LSTM_Models['10 neuron'][3].history['val_loss'],'k-.',label=Models['Names'][3])\r\n",
    "axs[0].legend() \r\n",
    "axs[0].title.set_text('10 neuron models')\r\n",
    "axs[0].set_ylabel('Loss')\r\n",
    "axs[0].set_xlabel('Epoch')\r\n",
    "\r\n",
    "axs[1].plot(LSTM_Models['50 neuron'][0].history['val_loss'],'g-.',label=Models['Names'][0])\r\n",
    "axs[1].plot(LSTM_Models['50 neuron'][1].history['val_loss'],'m-.',label=Models['Names'][1])\r\n",
    "axs[1].plot(LSTM_Models['50 neuron'][2].history['val_loss'],'b-.',label=Models['Names'][2])\r\n",
    "axs[1].plot(LSTM_Models['50 neuron'][3].history['val_loss'],'k-.',label=Models['Names'][3])\r\n",
    "axs[1].legend() \r\n",
    "axs[1].title.set_text('50 neuron models')\r\n",
    "axs[1].set_ylabel('Loss')\r\n",
    "axs[1].set_xlabel('Epoch')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, constrained_layout=True)\r\n",
    "fig.suptitle('LSTM model prediction')\r\n",
    "cut=-1\r\n",
    "axs[0].plot(LSTM_Preds['10 neuron'][0][:cut],'g-.',label='Short shallow pred')\r\n",
    "axs[0].plot(LSTM_Preds['10 neuron'][1][:cut],'m-.',label='Med shallow pred')\r\n",
    "axs[0].plot(LSTM_Preds['10 neuron'][2][:cut],'b-.',label='Long shallow pred')\r\n",
    "axs[0].plot(LSTM_Preds['10 neuron'][3][:cut],'k-.',label='Long deep pred')\r\n",
    "axs[0].plot(true_stock[:cut],'r',label='True',linewidth=2)\r\n",
    "axs[0].legend() \r\n",
    "axs[0].title.set_text('10 neuron models')\r\n",
    "axs[0].set_ylabel('Stock price')\r\n",
    "axs[0].set_xlabel('Period')\r\n",
    "\r\n",
    "axs[1].plot(LSTM_Preds['50 neuron'][0][:cut],'g-.',label='Short shallow pred')\r\n",
    "axs[1].plot(LSTM_Preds['50 neuron'][1][:cut],'m-.',label='Med shallow pred')\r\n",
    "axs[1].plot(LSTM_Preds['50 neuron'][2][:cut],'b-.',label='Long shallow pred')\r\n",
    "axs[1].plot(LSTM_Preds['50 neuron'][3][:cut],'k-.',label='Long deep pred')\r\n",
    "axs[1].plot(true_stock[:cut],'r',label='True',linewidth=2)\r\n",
    "axs[1].legend() \r\n",
    "axs[1].title.set_text('50 neuron models')\r\n",
    "axs[1].set_ylabel('Stock price')\r\n",
    "axs[1].set_xlabel('Period')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df=pd.DataFrame.from_dict(LSTM_Preds['10 neuron']).T\r\n",
    "preds_df2=pd.DataFrame.from_dict(LSTM_Preds['50 neuron']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_error=pd.DataFrame()\r\n",
    "res_error2=pd.DataFrame()\r\n",
    "for i in range(0,preds_df.shape[1]):\r\n",
    "    res_error[Models['Names'][i]]=preds_df[i]-true_stock\r\n",
    "    res_error2[Models['Names'][i]]=preds_df2[i]-true_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pal={res_error.columns[0]: 'g', res_error.columns[1]: 'm',res_error.columns[2]:'b', res_error.columns[3]:'gray'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,figsize=(15,12), constrained_layout=True)\r\n",
    "fig.suptitle('LSTM model prediction errors')\r\n",
    "sns.boxplot(data=res_error2,linewidth=1,fliersize=10,palette=custom_pal,ax=axs[0]).set(ylabel=\"Error\",xlabel=\"Models with 10 neurons\")\r\n",
    "sns.boxplot(data=res_error,linewidth=1,fliersize=10,palette=custom_pal,ax=axs[1]).set(ylabel=\"Error\",xlabel=\"Models with 50 neurons\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_acc=pd.DataFrame(columns=Models['Names'],index=['RMSE','MAPE'])\r\n",
    "fift_acc=pd.DataFrame(columns=Models['Names'])\r\n",
    "\r\n",
    "for i in range(4):\r\n",
    "    y_pred=LSTM_Preds['10 neuron'][i]\r\n",
    "    y_true=true_stock\r\n",
    "    ten_acc.loc['RMSE',Models['Names'][i]]=RMSE(y_true,y_pred)\r\n",
    "    ten_acc.loc['MAPE',Models['Names'][i]]=MAPE(y_true,y_pred)\r\n",
    "    \r\n",
    "for i in range(4):\r\n",
    "    y_pred=LSTM_Preds['50 neuron'][i]\r\n",
    "    y_true=true_stock\r\n",
    "    fift_acc.loc['RMSE',Models['Names'][i]]=RMSE(y_true,y_pred)\r\n",
    "    fift_acc.loc['MAPE',Models['Names'][i]]=MAPE(y_true,y_pred)\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ten_acc.style.set_caption('LSTM models with 10 neurons')),display(fift_acc.style.set_caption('LSTM models with 50 neurons'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(20,12), constrained_layout=True)\r\n",
    "fig.suptitle('LSTM model prediction errors')\r\n",
    "axs[0,0].barh(Models['Names'],ten_acc.iloc[0,:],color=colors)\r\n",
    "axs[0,1].barh(Models['Names'],ten_acc.iloc[1,:],color=colors)\r\n",
    "axs[1,0].barh(Models['Names'],fift_acc.iloc[0,:],color=colors)\r\n",
    "axs[1,1].barh(Models['Names'],fift_acc.iloc[1,:],color=colors)\r\n",
    "axs[0,0].set_xlabel('RMSE of LSTM with 10 neurons')\r\n",
    "axs[0,1].set_xlabel('MAPE of LSTM with 10 neurons')\r\n",
    "axs[1,0].set_xlabel('RMSE of LSTM with 50 neurons')\r\n",
    "axs[1,1].set_xlabel('MAPE of LSTM with 50 neurons')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python387jvsc74a57bd095ab7303ed2746327945aa376054eddca8c4eca362915ff95db932dbe7e7ee41"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "353721c5f85979d013650aa9fcdc7a8ab76bf3f3a79d9be3f9520ee5e62d21fb"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}