{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\r\n",
    "\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.style.use('ggplot')\r\n",
    "\r\n",
    "params = {'legend.fontsize': 'x-large',\r\n",
    "          'figure.figsize': (15, 15/1.6),\r\n",
    "         'axes.labelsize': 'x-large',\r\n",
    "         'axes.titlesize':'x-large',\r\n",
    "         'xtick.labelsize':'x-large',\r\n",
    "         'ytick.labelsize':'x-large'}\r\n",
    "plt.rcParams.update(params)\r\n",
    "\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import yfinance as yf\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\r\n",
    "\r\n",
    "from keras.models import Model\r\n",
    "from keras.models import Sequential\r\n",
    "from keras import optimizers\r\n",
    "from keras import layers\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t={'Models':'','Weights':[],'R_squared':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['Models']=['1 model','2 model','3 model']\r\n",
    "t['Weights']=[[0.11,0.21,0.11],[0.12,0.22,0.12],[0.13,0.23,0.13]]\r\n",
    "t['R_squared']=[0.25,0.60,0.92]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_hat,y_pred):\n",
    "    mape = np.mean(np.abs((y_hat - y_pred)/y_hat))*100\n",
    "    return mape\n",
    "\n",
    "def RMSE(y_hat,y_pred):\n",
    "    MSE = np.square(np.subtract(y_hat,y_pred)).mean() \n",
    "    return (MSE**(1/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_dev=tf.config.list_physical_devices(\"GPU\")\n",
    "if len(phys_dev)!=0:\n",
    "    tf.config.experimental.set_memory_growth(phys_dev[0],True)    \n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')),\"\\n\",\"Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\r\n",
    "EPOCHS=1000\r\n",
    "BATCH_SIZE=256\r\n",
    "RANDOMSEED=123\r\n",
    "\r\n",
    "SELECTED_STOCK='MSFT'\r\n",
    "\r\n",
    "np.random.seed(RANDOMSEED)\r\n",
    "python_random.seed(RANDOMSEED)\r\n",
    "tf.random.set_seed(RANDOMSEED)\r\n",
    "\r\n",
    "stock=yf.Ticker(SELECTED_STOCK).history(start='2015-01-01',end='2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\r\n",
    "    def __init__(self, data, target='Close',timeseries=True,scale=True,look_forw=1,look_back=60,test_size=0.2):\r\n",
    "    #Store the raw data.    \r\n",
    "        self.split=int(len(data)*(1-test_size))\r\n",
    "        self.Scaler=None\r\n",
    "        self.target_col=data.columns.get_loc(target)\r\n",
    "        self.look_forw = look_forw\r\n",
    "        self.look_back=look_back\r\n",
    "        self.train_dates=data.iloc[:self.split,:].index\r\n",
    "        self.test_dates=data.iloc[self.split-self.look_back:,:].index\r\n",
    "\r\n",
    "        #self.Data=data.dropna(subset=['Close'],how='any')   \r\n",
    "        \r\n",
    "        self.Train = np.array(data.iloc[:self.split,:])\r\n",
    "        self.Test = np.array(data.iloc[self.split-self.look_back:,:])\r\n",
    "\r\n",
    "        if timeseries==True:\r\n",
    "            self.Train=self.Train[:,self.target_col].reshape(-1,1)\r\n",
    "            self.Test=self.Test[:,self.target_col].reshape(-1,1)  \r\n",
    "        \r\n",
    "        if scale==True:\r\n",
    "            self.Scaler=MinMaxScaler(feature_range = (-1, 1))\r\n",
    "            self.Scaler=self.Scaler.fit(self.Train)\r\n",
    "        \r\n",
    "            self.Train=self.Scaler.transform(self.Train)\r\n",
    "            self.Test=self.Scaler.transform(self.Test)\r\n",
    "        \r\n",
    "        self.X_train_seq=[]\r\n",
    "        self.y_train_seq=[]\r\n",
    "        for i in range(self.look_back,len(self.Train)-self.look_forw+1):\r\n",
    "            self.X_train_seq.append(self.Train[i-self.look_back:i,:])\r\n",
    "                \r\n",
    "            if timeseries==True:\r\n",
    "                self.y_train_seq.append(self.Train[i+self.look_forw-1])\r\n",
    "            else:\r\n",
    "                self.y_train_seq.append(self.Train[i+self.look_forw-1,self.target_col])\r\n",
    "\r\n",
    "        self.X_train_seq=np.array(self.X_train_seq).astype('float32')\r\n",
    "        self.y_train_seq=np.array(self.y_train_seq,dtype='object').astype('float32')\r\n",
    "\r\n",
    "        self.X_train_seq=self.X_train_seq.reshape(self.X_train_seq.shape[0],self.X_train_seq.shape[1],self.X_train_seq.shape[2])\r\n",
    "\r\n",
    "        self.X_test_seq=[]\r\n",
    "        for i in range(self.look_back,len(self.Test)):\r\n",
    "                self.X_test_seq.append(self.Test[i-self.look_back:i,:])\r\n",
    "                \r\n",
    "        self.X_test_seq=np.asarray(self.X_test_seq).astype('float32')\r\n",
    "        self.X_test_seq=self.X_test_seq.reshape(self.X_test_seq.shape[0],self.X_test_seq.shape[1],self.X_test_seq.shape[2])\r\n",
    "\r\n",
    "        print(self.__repr__())\r\n",
    "\r\n",
    "    def __repr__(self):\r\n",
    "        return '\\n'.join([\r\n",
    "        f'Original train and test{self.Train.shape,self.Test.shape}',\r\n",
    "        f'X train size {self.X_train_seq.shape}',\r\n",
    "        f'Y train size: {self.y_train_seq.shape}',\r\n",
    "        f'X test size: {self.X_test_seq.shape}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Dataset(stock,look_back=60,look_forw=1,timeseries=True,scale=True)\r\n",
    "true_stock=stock.Close[data.split:].values\r\n",
    "input_shape=(data.look_back,data.X_train_seq.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mape=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "_rmse=tf.keras.metrics.RootMeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALLBACKS\r\n",
    "es=EarlyStopping(monitor='val_loss',min_delta=1e-3,mode=\"min\",patience=10,verbose=1)\r\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss',min_delta=1e-2,factor=0.75,cooldown=5,mode='min',patience=3,verbose=1)\r\n",
    "\r\n",
    "kernel_reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01)\r\n",
    "bias_reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01)\r\n",
    "recurrent_reg=keras.regularizers.l1_l2(l1=0.001, l2=0.001)\r\n",
    "act_reg=keras.regularizers.l1_l2(l1=0.001, l2=0.001)\r\n",
    "\r\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Models={'Name':[],'Model':[],'History':[],'Preds':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=input_shape),\r\n",
    "    layers.LSTM(units=50, return_sequences=False),\r\n",
    "    layers.Dense(units=data.y_train_seq.shape[1])\r\n",
    "]) \r\n",
    "  \r\n",
    "default_lstm.compile(optimizer=optimizer,loss=['mse'],metrics=[_mape])\r\n",
    "LSTM_Models['Name'].append('Default LSTM')\r\n",
    "LSTM_Models['Model'].append(default_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=input_shape,activation='linear'),\r\n",
    "    layers.Dropout(0.1),\r\n",
    "    layers.LSTM(units=50, return_sequences=False),\r\n",
    "    layers.Dropout(0.1),\r\n",
    "    layers.Dense(units=data.y_train_seq.shape[1])\r\n",
    "]) \r\n",
    "  \r\n",
    "base_lstm.compile(optimizer=optimizer,loss=['mse'],metrics=[_mape])\r\n",
    "LSTM_Models['Name'].append('Base LSTM')\r\n",
    "LSTM_Models['Model'].append(base_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelu_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=input_shape,activation='gelu'),\r\n",
    "    layers.Dropout(0.8),\r\n",
    "    layers.LSTM(units=50, return_sequences=False),\r\n",
    "    layers.Dropout(0.8),\r\n",
    "    layers.Dense(units=data.y_train_seq.shape[1])\r\n",
    "]) \r\n",
    "  \r\n",
    "gelu_lstm.compile(optimizer=optimizer,loss=['mse'],metrics=[_mape])\r\n",
    "LSTM_Models['Name'].append('GELU LSTM')\r\n",
    "LSTM_Models['Model'].append(gelu_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swish_lstm = Sequential([\r\n",
    "    layers.LSTM(units=50, return_sequences=True,input_shape=input_shape,activation='swish'),\r\n",
    "    layers.Dropout(0.1),\r\n",
    "    layers.LSTM(units=50, return_sequences=False),\r\n",
    "    layers.Dropout(0.1),\r\n",
    "    layers.Dense(units=data.y_train_seq.shape[1],activation='relu')\r\n",
    "]) \r\n",
    "  \r\n",
    "swish_lstm.compile(optimizer=optimizer,loss=['mse'],metrics=[_mape])\r\n",
    "LSTM_Models['Name'].append('Swish LSTM')\r\n",
    "LSTM_Models['Model'].append(swish_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in LSTM_Models['Model']:\r\n",
    "    history=model.fit(data.X_train_seq,data.y_train_seq, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1, verbose=0, callbacks=[es,rlr])\r\n",
    "    preds_scaled=model.predict(data.X_test_seq)\r\n",
    "    preds=data.Scaler.inverse_transform(np.repeat(preds_scaled,data.Train.shape[1],axis=1))[:,0]\r\n",
    "    LSTM_Models['Preds'].append(preds)\r\n",
    "    LSTM_Models['History'].append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in LSTM_Models['Preds']:\r\n",
    "    plt.plot(element,'-.')\r\n",
    "plt.plot(true_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_prediction=np.array(LSTM_Models['Preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_loss(weights):\n",
    "    weighted_preds=np.dot(weights,lstm_prediction)\n",
    "    return RMSE(true_stock.reshape(-1,1),weighted_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_weights = optimize.minimize(ensemble_loss,\r\n",
    "                                [1/len(LSTM_Models.keys())] * len(LSTM_Models.keys()),\r\n",
    "                                constraints=({'type': 'eq','fun': lambda w: 1-sum(w)}),\r\n",
    "                                method= 'SLSQP', \r\n",
    "                                bounds=[(0.0, 1.0)] * len(LSTM_Models.keys()),\r\n",
    "                                options = {'ftol':1e-10},\r\n",
    "                            )['x']\r\n",
    "preds=np.dot(opt_weights,lstm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds,'b-.',label='Prediction')\r\n",
    "plt.plot(true_stock,'r-.',label='True')\r\n",
    "plt.xlabel('Period')\r\n",
    "plt.title(f'LSTM ensemble prediction using for {SELECTED_STOCK}')\r\n",
    "plt.ylabel('Stock price')\r\n",
    "plt.legend()\r\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([f'R2 score: {r2_score(true_stock, preds)}',f'RMSE score: {RMSE(true_stock,preds)}',f'MAPE score: {MAPE(true_stock,preds)}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([f'R2 score: {r2_score(true_stock, preds)}',f'RMSE score: {RMSE(true_stock,preds)}',f'MAPE score: {MAPE(true_stock,preds)}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python387jvsc74a57bd095ab7303ed2746327945aa376054eddca8c4eca362915ff95db932dbe7e7ee41"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "353721c5f85979d013650aa9fcdc7a8ab76bf3f3a79d9be3f9520ee5e62d21fb"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}